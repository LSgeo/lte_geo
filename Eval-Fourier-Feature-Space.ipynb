{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ccbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import verde as vd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import models\n",
    "from mlnoddy.datasets import Norm, parse_geophysics\n",
    "from test import reshape\n",
    "from utils import to_pixel_samples\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f143768",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Norm(-10000, 10000, out_vals=(0, 1)).min_max_clip\n",
    "unnorm = Norm(-10000, 10000, out_vals=(0, 1)).inverse_mmc\n",
    "\n",
    "\n",
    "def subsample(raster, ls):\n",
    "    \"\"\"Select points from raster according to line spacing\"\"\"\n",
    "    # input_cell_size = 20 # Noddyverse cell size is 20 m\n",
    "    ss = 1  # Sample every n points along line\n",
    "\n",
    "    x, y = np.meshgrid(\n",
    "        np.arange(raster.shape[-1]), np.arange(raster.shape[-2]), indexing=\"xy\"\n",
    "    )\n",
    "    x = x[::ss, ::ls]\n",
    "    y = y[::ss, ::ls]\n",
    "    vals = raster.numpy()[:, ::ss, ::ls].squeeze()  # shape for gridding\n",
    "\n",
    "    return x, y, vals\n",
    "\n",
    "\n",
    "def grid(x, y, z, ls, cs_fac=4, d=180):\n",
    "    \"\"\"Min Curvature grid xyz at scale, with ls/cs_fac cell size.\n",
    "    Params:\n",
    "        d: adjustable crop factor, but 180 is best for noddyverse. 200 Max.\n",
    "    \"\"\"\n",
    "    w, e, s, n = np.array([0, d, 0, d], dtype=np.float32)\n",
    "    cs = ls / cs_fac  # Cell size is e.g. 1/4 line spacing\n",
    "    gridder = vd.ScipyGridder(\"cubic\")\n",
    "    gridder = gridder.fit(coordinates=(x, y), data=z)\n",
    "    grid = gridder.grid(\n",
    "        data_names=\"forward\",\n",
    "        coordinates=np.meshgrid(\n",
    "            np.arange(w, e, step=cs),\n",
    "            np.arange(s, n, step=cs),\n",
    "            indexing=\"xy\",\n",
    "        ),\n",
    "    )\n",
    "    grid = grid.get(\"forward\").values.astype(np.float32)\n",
    "\n",
    "    return np.expand_dims(grid, 0)  # add channel dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a2ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"D:/luke/lte_geo/save/_train_swinir-lte_geo/230308-1738_joint_fly_346/joint_fly_346_epoch-last.pth\"\n",
    "# model_path = \"D:/luke/lte_geo/save/_train_swinir-lte_geo/230517-0911_spotty_airport_6488/spotty_airport_6488_epoch-last.pth\"\n",
    "# model_path = \"D:/luke/lte_geo/save/_train_swinir-lte_geo/230512-1658_extra_squid_2420/extra_squid_2420_epoch-last.pth\"\n",
    "# model_path = \"D:/luke/lte_geo/save/_train_swinir-lte_geo/230516-1847_resident_crumble_3867/resident_crumble_3867_epoch-last.pth\"\n",
    "# fpath = \"D:/luke/Noddy_data/Noddy_1M/DYKE_DYKE_DYKE/models_by_code/models/DYKE_DYKE_DYKE/20-09-04-16-04-59-857118037.g12\"\n",
    "fpath = \"D:/luke/Noddy_data/Noddy_1M/DYKE_DYKE_FOLD/models_by_code/models/DYKE_DYKE_FOLD/20-09-04-18-53-46-989190706.g12\"\n",
    "\n",
    "# model_path = \"D:/luke/edsr-baseline-lte.pth\"\n",
    "\n",
    "model_spec = torch.load(model_path)[\"model\"]\n",
    "model = models.make(model_spec, load_sd=True).cuda()\n",
    "\n",
    "hr_ls = 4\n",
    "scale = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b978ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "which = 1\n",
    "\n",
    "if which == 0:\n",
    "    # Synthetic Fourier plot\n",
    "    dim = 180\n",
    "    im = np.zeros((3, dim, dim))\n",
    "    s = dim // scale\n",
    "    e = (dim - s) // 2\n",
    "    # im[:, 128] = 1\n",
    "    im[::2, :] = 1\n",
    "    gt = torch.from_numpy(im)\n",
    "    gt = gt.to(torch.float32)\n",
    "    lr = gt[:, :, e:-e, e:-e]  # shit downsampling implementation\n",
    "    # lr = lr.unsqueeze(0)\n",
    "\n",
    "\n",
    "elif which == 1:\n",
    "    # Noddy Model\n",
    "    mag = parse_geophysics(Path(fpath), mag=True)\n",
    "    mag = torch.from_numpy(next(mag)).unsqueeze(0)\n",
    "\n",
    "    x, y, vals = subsample(mag, ls=hr_ls)\n",
    "    gt = torch.from_numpy(norm(grid(x, y, vals, ls=hr_ls))).to(torch.float32)\n",
    "    x, y, vals = subsample(mag, ls=hr_ls * scale)\n",
    "    lr = torch.from_numpy(norm(grid(x, y, vals, ls=hr_ls * scale))).to(torch.float32)\n",
    "\n",
    "elif which == 2:\n",
    "    scale = 2\n",
    "    lr_path = \"D:/luke/Flickr_-_paul_bica_-_vanishing_point.jpg\"\n",
    "    xx = 360\n",
    "    yy = 660\n",
    "    obs_size = 120\n",
    "\n",
    "    from torchvision import transforms\n",
    "    from PIL import Image\n",
    "\n",
    "    # load image\n",
    "    gt = transforms.ToTensor()(Image.open(lr_path).convert('RGB'))\n",
    "    gt = gt[:, 720-120:720+120, 1320-120:1320+120].contiguous()\n",
    "    img_lr = transforms.Resize(gt.shape[1] // 2)(gt).contiguous()\n",
    "    lr = (img_lr - 0.5) / 0.5\n",
    "\n",
    "    from PIL import ImageDraw\n",
    "\n",
    "    # Display GT\n",
    "    im = transforms.ToPILImage()(lr)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.rectangle([yy-obs_size//2, xx-obs_size//2, yy+obs_size//2, xx+obs_size//2], outline=\"red\", width=3)\n",
    "    display(im)\n",
    "\n",
    "\n",
    "hr_coord, hr_val = to_pixel_samples(gt)\n",
    "\n",
    "hr_cell = torch.ones_like(hr_coord)\n",
    "hr_cell[:, 0] *= 2 / gt.shape[-2]\n",
    "hr_cell[:, 1] *= 2 / gt.shape[-1]\n",
    "\n",
    "gt = gt.unsqueeze(0)\n",
    "lr = lr.unsqueeze(0)\n",
    "hr_coord = hr_coord.unsqueeze(0)\n",
    "hr_cell = hr_cell.unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad75777",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt.shape, lr.shape, hr_coord.shape, hr_cell.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a464e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "inp = lr.to(\"cuda\", non_blocking=True)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # model.gen_feat(\n",
    "    #     inp.flip(-2)\n",
    "    # )  # due to a digital image coordinate conventions (https://blogs.mathworks.com/steve/2011/08/26/digital-image-processing-using-matlab-digital-image-representation/)\n",
    "\n",
    "    sr = (\n",
    "        model(\n",
    "            inp.flip(-2),\n",
    "            hr_coord.to(\"cuda\", non_blocking=True),\n",
    "            hr_cell.to(\"cuda\", non_blocking=True),\n",
    "        )\n",
    "        .detach()\n",
    "        .cpu()\n",
    "    )\n",
    "    freq = model.coeff.flip(-2)\n",
    "    coef = model.freqq.flip(-2)\n",
    "\n",
    "sr, batch = reshape(dict(inp=lr, coord=hr_coord, gt=gt), 0, 0, hr_coord, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freq.shape)\n",
    "print(len(torch.split(freq, 2, dim=1)))\n",
    "print(torch.split(freq, 2, dim=1)[0].shape)\n",
    "print(torch.stack(torch.split(freq, 2, dim=1), dim=2).shape)\n",
    "\n",
    "freq_x = torch.stack(torch.split(freq, 2, dim=1), dim=2)[0, 1, :, 0, 0]\n",
    "freq_y = torch.stack(torch.split(freq, 2, dim=1), dim=2)[0, 0, :, 0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c54b16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "arr = (\n",
    "    # (((torch.stack((gt, gt, gt)) + 1) * 128) - 1)\n",
    "    # (torch.stack((gt, gt, gt)))\n",
    "    gt.squeeze()\n",
    "    # .permute(1, 2, 0)\n",
    "    .numpy().astype(\"uint8\")\n",
    ")\n",
    "\n",
    "vmin = sr.min()\n",
    "vmax = gt.max()\n",
    "\n",
    "fig, [axlr, axsr, axhr] = plt.subplots(1, 3, constrained_layout=True, figsize=(15, 5))\n",
    "plt.suptitle(Path(model_path).stem.split(\"_epoch\")[0])\n",
    "srh = axhr.imshow(gt.squeeze(), vmin=vmin, vmax=vmax) # .permute(1,2,0)\n",
    "# plt.colorbar(srh, ax=axhr)\n",
    "axlr.imshow(lr.squeeze(), vmin=vmin, vmax=vmax) # .permute(1,2,0) * 0.5 + 0.5\n",
    "src = axsr.imshow(sr.squeeze(), vmin=vmin, vmax=vmax, origin=\"lower\") #.permute(1,2,0) * 0.5 + 0.5\n",
    "# plt.colorbar(src, ax=axsr)\n",
    "axhr.set_title(\"hr\")\n",
    "axlr.set_title(\"lr\")\n",
    "axsr.set_title(\"sr\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Fourier Feature Space\n",
    "# freq = model.freq(model.feat)\n",
    "# coef = model.coef(model.feat)\n",
    "\n",
    "\n",
    "def plot_F_features(freq, coef):\n",
    "    \"\"\"Plot LTE extracted Fourier Features\"\"\"\n",
    "    freq_x = torch.stack(torch.split(freq, 2, dim=1), dim=2)[0, 1, :, 0, 0]\n",
    "    freq_y = torch.stack(torch.split(freq, 2, dim=1), dim=2)[0, 0, :, 0, 0]\n",
    "    mag = (\n",
    "        coef[0, : freq.shape[1] // 2, 0, 0] ** 2\n",
    "        + coef[0, freq.shape[1] // 2 :, 0, 0] ** 2\n",
    "    )\n",
    "    plt.figure(figsize=(6, 6), constrained_layout=True)\n",
    "    plt.title(Path(model_path).stem.split(\"_epoch\")[0])\n",
    "    sc = plt.scatter(\n",
    "        freq_x.cpu().numpy(),\n",
    "        freq_y.cpu().numpy(),\n",
    "        c=mag.cpu().numpy(),\n",
    "        vmin=0,\n",
    "        vmax=max(mag.cpu().numpy()) / 4,\n",
    "        s=25,\n",
    "        # alpha=0.5,\n",
    "        linewidths=0,\n",
    "        cmap=\"bwr\",\n",
    "    )\n",
    "    # plt.colorbar(sc)\n",
    "    plt.xticks(np.linspace(-1.5, 1.5, 5))\n",
    "    plt.yticks(np.linspace(-1.5, 1.5, 5))\n",
    "    # plt.axis(\"equal\")\n",
    "\n",
    "\n",
    "plot_F_features(freq, coef)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4206ac95",
   "metadata": {},
   "source": [
    "And the DFT version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.fft\n",
    "import scipy.stats\n",
    "import tifffile\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "# im = lr.squeeze().numpy()[0, :, : ]\n",
    "im = lr.numpy().squeeze()\n",
    "\n",
    "arr = im\n",
    "cell_size = (\n",
    "    20  # m / pixel # We are working with rasters that cover a specific size area\n",
    ")\n",
    "original_shape = arr.shape\n",
    "\n",
    "# plt.imshow(arr, cmap=cc.cm.CET_L1); plt.title(\"Input Array\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeff1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_y = scipy.fft.next_fast_len(arr.shape[0])\n",
    "fast_x = scipy.fft.next_fast_len(arr.shape[1])\n",
    "while fast_y % 2 > 0:  # It is useful later on that we get an even number\n",
    "    fast_y = scipy.fft.next_fast_len(fast_y + 1)\n",
    "while fast_x % 2 > 0:\n",
    "    fast_x = scipy.fft.next_fast_len(fast_x + 1)\n",
    "\n",
    "print(f\"Original shape (y, x): {original_shape}\")\n",
    "print(f\"Next even efficient sizes (y, x): {(fast_y, fast_x)}\")\n",
    "\n",
    "pad_arr = np.pad(\n",
    "    arr,\n",
    "    pad_width=((0, fast_y - arr.shape[0]), (0, fast_x - arr.shape[1])),\n",
    "    constant_values=0,\n",
    ")\n",
    "print(f\"New padded array shape (y, x): {pad_arr.shape}\")\n",
    "# print(f\"New padded array spatial extent (y, x): {(pad_arr.shape[0] * cell_size, pad_arr.shape[1] * cell_size)}m\") # irrelevant\n",
    "\n",
    "plt.imshow(pad_arr, cmap=cc.cm.CET_L1)\n",
    "plt.title(\"Padded input image\")\n",
    "plt.axhline(arr.shape[0], c=\"r\")\n",
    "plt.axvline(arr.shape[1], c=\"r\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027f70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_arr = scipy.fft.fft2(arr)\n",
    "\n",
    "def make_F_plots(in_arr, ax_args={}, shift=True):\n",
    "    \"\"\"We will reuse this plot layout several times\n",
    "    in_arr: input array\n",
    "    ax_args: Axes arguements shared using a single dictionary\n",
    "    shift: Used to specify if in_arr is in an un-shifted FFT domain\n",
    "    \"\"\"\n",
    "\n",
    "    ax_args = {\n",
    "        **ax_args,\n",
    "        \"cmap\": \"bwr\",\n",
    "        \"vmin\": 0,\n",
    "        \"vmax\": np.log(1 + np.abs(in_arr) ** 2).max(),\n",
    "    }  # Spoiler alert - this is just to set a common colour map.\n",
    "    fftshift = (\n",
    "        scipy.fft.fftshift if shift else lambda i: i\n",
    "    )  # Whether to shift the domain to DC at origin or do nothing\n",
    "    extent = ax_args.get(\"extent\")\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    F_magnitude_spectrum = np.abs(in_arr)  # Fourier Magnitude Spectrum\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title(\"Input Magnitude Spectrum\")\n",
    "    plt.imshow(np.log(1 + F_magnitude_spectrum), **ax_args)\n",
    "    plt.colorbar(orientation=\"horizontal\")\n",
    "    if extent:\n",
    "        plt.ylim(extent[2], extent[3])\n",
    "        plt.xlim(extent[0], extent[1])\n",
    "        plt.axis(\"equal\")\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title((\"Shifted \" if shift else \"\") + \"Magnitude Spectrum\")\n",
    "    plt.imshow(\n",
    "        np.log(1 + fftshift(F_magnitude_spectrum)), **ax_args\n",
    "    )  # Easier to interpret Fourier Magnitude Spectrum\n",
    "    plt.colorbar(orientation=\"horizontal\")\n",
    "    if extent:\n",
    "        plt.ylim(extent[2], extent[3])\n",
    "        plt.xlim(extent[0], extent[1])\n",
    "        plt.axis(\"equal\")\n",
    "\n",
    "    F_power_spectrum = np.abs(in_arr) ** 2  # Fourier Power Spectrum\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title((\"Shifted \" if shift else \"\") + \"Power Spectrum\")\n",
    "    plt.imshow(np.log(1 + fftshift(F_power_spectrum)), **ax_args)\n",
    "    plt.colorbar(orientation=\"horizontal\", label=\"Amplitude\")\n",
    "    if extent:\n",
    "        plt.ylim(extent[2], extent[3])\n",
    "        plt.xlim(extent[0], extent[1])\n",
    "        plt.axis(\"equal\")\n",
    "\n",
    "    F_phase = np.angle(in_arr) / np.pi  # Fourier Phase Spectrum\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title((\"Shifted \" if shift else \"\") + \"Phase\")\n",
    "    plt.imshow(fftshift(F_phase), cmap=ax_args[\"cmap\"], vmin=-1, vmax=1)\n",
    "    plt.colorbar(orientation=\"horizontal\", label=\"$\\pi$\")\n",
    "    if extent:\n",
    "        plt.ylim(extent[2], extent[3])\n",
    "        plt.xlim(extent[0], extent[1])\n",
    "        plt.axis(\"equal\")\n",
    "\n",
    "freqs = scipy.fft.fftshift(scipy.fft.fftfreq(pad_arr.shape[0], 1))\n",
    "make_F_plots(F_arr, {\"extent\": [freqs[0], freqs[-1], freqs[0], freqs[-1]]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33c2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced55d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('lte')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "05781e052d06f1cdf1bacfc411fbd68c6efd2f4a84155de6239f578257f46815"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
