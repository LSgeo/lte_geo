{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import datasets as dsets\n",
    "import models\n",
    "import utils\n",
    "from test import reshape, batched_predict\n",
    "from mlnoddy.datasets import parse_geophysics, Norm\n",
    "\n",
    "import rasterio\n",
    "import tifffile\n",
    "from datasets.noddyverse import HRLRNoddyverse, NoddyverseWrapper\n",
    "from datasets.noddyverse import load_naprstek_synthetic as load_naprstek\n",
    "\n",
    "from inference import (\n",
    "    load_model,\n",
    "    load_real_data,\n",
    "    input_tiler,\n",
    "    real_inference,\n",
    "    test_custom_data,\n",
    "    CustomTestDataset,\n",
    "    eval,\n",
    "    plot_canny,\n",
    "    plt_results,\n",
    "    save_pred,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/inference.yaml\", \"r\") as f:\n",
    "        cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "scale = 4\n",
    "filepath = Path(r\"D:/luke/data_source/P1134/P1134-grid-tmi.ers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\luke\\Miniconda3\\envs\\lte\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: D:\\luke\\lte_geo\\save\\_train_swinir-lte_geo\\221113-1221_average_aerator_7080\\average_aerator_7080_epoch-last.pth\n",
      "Saving to: d:\\luke\\lte_geo\\inference\\average_aerator\n"
     ]
    }
   ],
   "source": [
    "model, model_name, model_paths = load_model(cfg)\n",
    "# Define Data ###\n",
    "\n",
    "spec = cfg[\"test_dataset\"]\n",
    "dataset = dsets.make(spec[\"dataset\"])\n",
    "dataset = dsets.make(spec[\"wrapper\"], args={\"dataset\": dataset})\n",
    "# dataset.crop = spec[\"wrapper\"][\"args\"][\"crop\"]\n",
    "# ^ this should now be handled in .make()\n",
    "\n",
    "if cfg[\"limit_to_plots\"]:\n",
    "    dataset = Subset(dataset, cfg[\"plot_samples\"])\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=spec[\"batch_size\"],\n",
    "    num_workers=cfg.get(\"num_workers\"),\n",
    "    persistent_workers=bool(cfg.get(\"num_workers\")),\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# Pack Options ###\n",
    "opts = dict(\n",
    "    model_name=model_name,\n",
    "    model_path=model_paths[0],\n",
    "    save_path=Path(cfg[\"inference_output_dir\"] or f\"inference/{model_name}\"),\n",
    "    rgb_range=cfg[\"rgb_range\"],\n",
    "    shave_factor=3,  # pixels to shave (edges may include NaN)\n",
    "    ids=cfg[\"plot_samples\"],  # Sample IDs\n",
    "    mag=cfg[\"test_dataset\"][\"dataset\"][\"args\"][\"load_magnetics\"],\n",
    "    grv=cfg[\"test_dataset\"][\"dataset\"][\"args\"][\"load_gravity\"],\n",
    "    eval_bsize=cfg[\"eval_bsize\"],\n",
    "    limit_to_plots=cfg[\"limit_to_plots\"],\n",
    "    gt_list=cfg[\"test_dataset\"][\"dataset\"][\"args\"][\"root_path\"]\n",
    "\n",
    ")\n",
    "\n",
    "scale_min = spec[\"wrapper\"][\"args\"][\"scale_min\"]\n",
    "scale_max = spec[\"wrapper\"][\"args\"][\"scale_max\"]\n",
    "\n",
    "print(\n",
    "    f\"\\nModel: {opts['model_path'].absolute()}\\n\"\n",
    "    f\"Saving to: {opts['save_path'].absolute()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do Inference ###\n",
    "# results_dict = {}\n",
    "# custom_results_dict = {}\n",
    "\n",
    "# scale_min = 4\n",
    "# scale_max = 4\n",
    "\n",
    "# pbar_m = tqdm(range(scale_min, scale_max + 1))\n",
    "# for scale in pbar_m:\n",
    "#     pbar_m.set_description(f\"{scale}x scale\")\n",
    "#     opts[\"shave\"] = scale * opts[\"shave_factor\"]\n",
    "\n",
    "#     # lazy way to reset custom grid opts\n",
    "#     opts[\"ids\"] = cfg[\"plot_samples\"]\n",
    "#     opts[\"gt\"] = None\n",
    "#     opts[\"set\"] = \"test\"\n",
    "\n",
    "#     dataset.scale = scale\n",
    "#     dataset.scale_min = scale\n",
    "#     dataset.scale_max = scale\n",
    "#     if cfg[\"limit_to_plots\"]:\n",
    "#         # Not sure how to better handle Subset dataset\n",
    "#         dataset.dataset.scale = scale\n",
    "#         dataset.dataset.scale_min = scale\n",
    "#         dataset.dataset.scale_max = scale\n",
    "\n",
    "#     results = eval(model, scale, loader, opts, cfg=cfg)\n",
    "#     results_dict[f\"{scale}x\"] = results\n",
    "#     pbar_m.write(f\"{scale}x scale - Mean:\")\n",
    "#     pbar_m.write(\n",
    "#         \", \".join(\n",
    "#             f\"{metric_name}: {metric_value:.4f}\"\n",
    "#             for metric_name, metric_value in results.items()\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_results(results_dict, opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i, batch in enumerate(loader):\n",
    "    inp = batch[\"inp\"].to(\"cuda\", non_blocking=True)\n",
    "    coord = batch[\"coord\"].to(\"cuda\", non_blocking=True)\n",
    "    cell = batch[\"cell\"].to(\"cuda\", non_blocking=True)\n",
    "    # batch[\"gt\"] = batch[\"gt\"].to(\"cuda\", non_blocking=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if opts[\"eval_bsize\"]:\n",
    "            pred = batched_predict(model, inp, coord, cell, opts[\"eval_bsize\"])\n",
    "        else:\n",
    "            pred = model(inp, coord, cell)\n",
    "\n",
    "    pred, batch = reshape(batch, h_pad=0, w_pad=0, coord=coord, pred=pred)\n",
    "    lr = batch[\"inp\"].detach().cpu().squeeze().numpy()\n",
    "    hr = batch[\"gt\"].detach().cpu().squeeze().numpy()\n",
    "    sr = pred.detach().cpu().squeeze().numpy()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "from inference import plot_canny\n",
    "sigma = 1.0\n",
    "low_threshold = -0.2\n",
    "high_threshold = 0.2  # Normalised -1 to 1 \n",
    "\n",
    "# plt.figure(constrained_layout=True)\n",
    "# plt.subplot(2,4,1)\n",
    "# plt.imshow(batch[\"gt\"].cpu().squeeze().numpy())\n",
    "# plt.subplot(2,4,2)\n",
    "# plt.imshow(lr)\n",
    "# plt.subplot(2,4,3)\n",
    "# plt.imshow(sr)\n",
    "# plt.subplot(2,4,4)\n",
    "# plt.imshow(hr)\n",
    "# plt.colorbar()\n",
    "# plt.subplot(2,4,5)\n",
    "# plt.imshow(canny(batch[\"gt\"].cpu().squeeze().numpy(), sigma, low_threshold, high_threshold))\n",
    "# plt.subplot(2,4,6)\n",
    "# plt.imshow(canny(lr, sigma, low_threshold, high_threshold))\n",
    "# plt.subplot(2,4,7)\n",
    "# plt.imshow(canny(sr, sigma, low_threshold, high_threshold))\n",
    "# plt.subplot(2,4,8)\n",
    "# plt.imshow(canny(hr, sigma, low_threshold, high_threshold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('lte')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05781e052d06f1cdf1bacfc411fbd68c6efd2f4a84155de6239f578257f46815"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
