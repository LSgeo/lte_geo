{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geophysics:  \n",
    "- 3.33 inches for one-column figures\n",
    "- 4.33 inches, for one-and-one-third-column\n",
    "\n",
    "- graph labels 8-point sans serif font such as Arial or Helvetica?\n",
    "- first letter of graph labels capitalized\n",
    "- abscissa and ordinate of each graph labeled, units denoted in parentheses\n",
    "- Title heading for each graph\n",
    "- en dash instead of a hyphen to denote subtraction and negative numbers?\n",
    "- Consistent style with those in other figures, especially similar figures?\n",
    "- labels on vertical axes: read from left to right when you rotate the page **clockwise 90Â°**), centered vertically?\n",
    "- Are scalars italicized consistently in text, figures, and figure captions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set rc params\n",
    "# https://matplotlib.org/stable/tutorials/introductory/customizing.html#the-matplotlibrc-file\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"font.size\"] = 8.0\n",
    "mpl.rcParams[\"figure.dpi\"] = 100 #600\n",
    "mpl.rcParams[\"figure.figsize\"] = (4.3, 8.6)\n",
    "mpl.rcParams[\"figure.constrained_layout.use\"] = True\n",
    "mpl.rcParams[\"image.origin\"] = \"lower\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import colorcet as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import datasets as dsets\n",
    "import models\n",
    "import utils\n",
    "from test import reshape, batched_predict\n",
    "from mlnoddy.datasets import parse_geophysics, Norm\n",
    "\n",
    "import rasterio\n",
    "import tifffile\n",
    "from datasets.noddyverse import HRLRNoddyverse, NoddyverseWrapper\n",
    "from datasets.noddyverse import load_naprstek_synthetic as load_naprstek\n",
    "\n",
    "from inference import (\n",
    "    CustomTestDataset,\n",
    "    load_model,\n",
    "    load_real_data,\n",
    "    input_tiler,\n",
    "    real_inference,\n",
    "    test_custom_data,\n",
    "    eval,\n",
    "    plot_gt,\n",
    "    plot_canny,\n",
    "    plt_results,\n",
    "    save_pred,\n",
    ")\n",
    "\n",
    "with open(\"configs/train_swinir-lte_geo.yaml\", \"r\") as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Line spacings, sample factors, cell sizes, etc #\n",
    "\n",
    "\n",
    "def tabulate_scale_info(\n",
    "    hr_scale_fac=4,  # Every nth line for HR\n",
    "    cs_factor=4,  # 1/4 per Reid 1980, 1/5 per GA\n",
    "    crop_dim=180,  # cells\n",
    "    max_scale=10,\n",
    "):\n",
    "    \"\"\"Print Line spacings, sample factors, cell sizes, etc, per scale\"\"\"\n",
    "    cs_factor = 1 / cs_factor\n",
    "    noddy_cs = 20  # m\n",
    "    noddy_dim = 200  # cells\n",
    "    noddy_extent = noddy_cs * noddy_dim  # m\n",
    "    crop_extent = crop_dim * noddy_cs\n",
    "    scale_factors = range(1, max_scale + 1)\n",
    "\n",
    "    hr_line_spacing = noddy_cs * hr_scale_fac\n",
    "    print(\"Scale | Line spacing | Cell size | LR Dimensions | Sample Q\")\n",
    "    for scale in scale_factors:\n",
    "        print(\n",
    "            f\" {scale:02} x |\"\n",
    "            f\"     {(ls := hr_scale_fac * scale * noddy_cs):03} m    |\"\n",
    "            f\"   {(cs := ls * cs_factor):03.0f} m   |\"\n",
    "            f\"  {(dim := crop_extent / cs):05.1f} cells  |\"\n",
    "            f\" {(dim**2):03.1f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def dumpforcfg(hr_scale_fac=4, cs_factor=4, crop_dim=180, max_scale=10):\n",
    "    \"\"\"To copy and paste values into cfg\"\"\"\n",
    "\n",
    "    cs_factor = 1 / cs_factor\n",
    "    noddy_cs = 20  # m\n",
    "    noddy_dim = 200  # cells\n",
    "    noddy_extent = noddy_cs * noddy_dim  # m\n",
    "    crop_extent = crop_dim * noddy_cs\n",
    "    scale_factors = range(1, max_scale + 1)\n",
    "\n",
    "    hr_line_spacing = noddy_cs * hr_scale_fac\n",
    "\n",
    "    for scale in scale_factors:\n",
    "        ls = hr_scale_fac * scale * noddy_cs\n",
    "        cs = ls * cs_factor\n",
    "\n",
    "        print(\n",
    "            \"\\n\"\n",
    "            f\"      inp_size: {(dim := crop_extent / cs):0.0f}\\n\"\n",
    "            f\"      sample_q: {(dim**2):03.0f}\\n\"\n",
    "            f\"      scale_min: {scale}\\n\"\n",
    "            f\"      scale_max: {scale}\",\n",
    "        )\n",
    "\n",
    "\n",
    "# tabulate_scale_info(hr_scale_fac=4)\n",
    "dumpforcfg(hr_scale_fac=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Noddy model with specific ID ##\n",
    "\n",
    "with open(\"configs/train_swinir-lte_geo.yaml\", \"r\") as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "args = cfg[\"train_dataset\"][\"dataset\"][\"args\"]\n",
    "dset = HRLRNoddyverse(\n",
    "    root_path=args[\"root_path\"],\n",
    "    norm=args[\"norm\"],\n",
    "    noddylist=args[\"noddylist\"],\n",
    "    blocklist=args[\"blocklist\"],\n",
    "    hr_line_spacing=args[\"hr_line_spacing\"],\n",
    "    load_magnetics=args[\"load_magnetics\"],\n",
    ")\n",
    "dset.scale = 4\n",
    "unorm = Norm(args[\"norm\"][0], args[\"norm\"][1]).inverse_mmc\n",
    "\n",
    "noddydir = \"C:/Users/Public/scratch/Noddy_1M/PLUG_PLUG_FOLD/models_by_code/models/PLUG_PLUG_FOLD/20-09-10-14-45-47-034629522\"\n",
    "noddystr = \"20-09-10-14-45-47-034629522\"\n",
    "\n",
    "for sample_id in (\n",
    "    -7955,\n",
    "    -7904,\n",
    "    -7844,\n",
    "    -7826,\n",
    "    -7779,\n",
    "    -7700\n",
    "    # range(\n",
    "    # cfg[\"val_dataset\"][\"dataset\"][\"args\"][\"use_dset_slice\"][0],\n",
    "    # cfg[\"val_dataset\"][\"dataset\"][\"args\"][\"use_dset_slice\"][1])\n",
    "):\n",
    "    plt.figure()\n",
    "    plt.title(f\"Sample {sample_id}\")\n",
    "    plt.imshow(dset[sample_id][\"gt_grid\"].squeeze())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot all GT and low resolution grids ##\n",
    "\n",
    "with open(\"configs/train_swinir-lte_geo.yaml\", \"r\") as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "sample_id = cfg[\"val_dataset\"][\"dataset\"][\"args\"][\"use_dset_slice\"][0]\n",
    "sample_id += 29\n",
    "sample_id = -7779\n",
    "max_scale = 6\n",
    "scale_range = (6,7)  # range(1, max_scale + 1, 2)\n",
    "\n",
    "\n",
    "args = cfg[\"train_dataset\"][\"dataset\"][\"args\"]\n",
    "dset = HRLRNoddyverse(\n",
    "    root_path=args[\"root_path\"],\n",
    "    norm=args[\"norm\"],\n",
    "    noddylist=args[\"noddylist\"],\n",
    "    blocklist=args[\"blocklist\"],\n",
    "    hr_line_spacing=args[\"hr_line_spacing\"],\n",
    "    load_magnetics=args[\"load_magnetics\"],\n",
    ")\n",
    "dset.scale = 1\n",
    "unorm = Norm(args[\"norm\"][0], args[\"norm\"][1]).inverse_mmc\n",
    "\n",
    "grids = {}\n",
    "\n",
    "for scale in tqdm(scale_range):\n",
    "    dset.scale = scale\n",
    "    grids[f\"{scale}x\"] = (dset[sample_id][\"gt_grid\"], dset[sample_id][\"lr_grid\"])\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, len(scale_range))\n",
    "plt.suptitle(f\"Sample {sample_id}\")\n",
    "for [axgt, axlr], grid in zip(axes.T, grids):\n",
    "    axgt.set_title(grid)\n",
    "    plot_gt(axgt, grids[grid][0].squeeze(), args, scale=int(grid[:-1]))\n",
    "\n",
    "    cbar = axlr.imshow(\n",
    "        unorm(grids[grid][1]).squeeze(),\n",
    "        interpolation=\"nearest\",\n",
    "        origin=\"lower\",\n",
    "        cmap=cc.cm.CET_L1,\n",
    "    )\n",
    "    plt.colorbar(mappable=cbar, ax=axlr, orientation=\"horizontal\")\n",
    "\n",
    "plt.savefig(f\"LR samples_{sample_id}.png\", facecolor=\"white\", transparent=False)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST IQA ###\n",
    "\n",
    "from pathlib import Path\n",
    "import piq\n",
    "import torch\n",
    "\n",
    "import datasets\n",
    "from mlnoddy.datasets import Norm, parse_geophysics\n",
    "\n",
    "norm = Norm(-10000, 10000, out_vals=(0, 1)).min_max_clip\n",
    "unnorm = Norm(-10000, 10000, out_vals=(0, 1)).inverse_mmc\n",
    "\n",
    "t1 = parse_geophysics(Path(\"D:/luke/Noddy_data/Noddy_1M/DYKE_DYKE_DYKE/models_by_code/models/DYKE_DYKE_DYKE/20-09-04-15-13-14-866983543.his\"), mag=True)\n",
    "t1 = torch.from_numpy(next(t1)).unsqueeze(0).unsqueeze(0)\n",
    "t1 = norm(t1)\n",
    "\n",
    "t1.clamp_(0,1)\n",
    "# print(t1)\n",
    "\n",
    "t2 = parse_geophysics(Path(\"D:/luke/Noddy_data/Noddy_1M/DYKE_DYKE_DYKE/models_by_code/models/DYKE_DYKE_DYKE/20-09-04-15-13-14-866983543.his\"), mag=True)\n",
    "t2 = torch.from_numpy(next(t2)).unsqueeze(0).unsqueeze(0)\n",
    "t2 = norm(t2) - torch.rand_like(t2) * 0.1\n",
    "t2.clamp_(0,1)\n",
    "# print(t2)\n",
    "\n",
    "print(piq.FSIMLoss(chromatic=False)(t1, t2))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(t1.numpy().squeeze())\n",
    "plt.figure()\n",
    "plt.imshow(t2.numpy().squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot performance of all models on Noddy Synthetic ###\n",
    "\n",
    "with open(\"configs/inference.yaml\", \"r\") as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "names = cfg[\"range_model_names\"][::-1][:1]\n",
    "scales = cfg[\"range_model_scales\"][::-1][:1]\n",
    "\n",
    "# inp_sizes = 180 / scales\n",
    "\n",
    "\n",
    "# Define Data ###\n",
    "spec = cfg[\"test_dataset\"]\n",
    "dataset = dsets.make(spec[\"dataset\"])\n",
    "dataset = dsets.make(spec[\"wrapper\"], args={\"dataset\": dataset})\n",
    "\n",
    "if cfg[\"limit_to_plots\"]:\n",
    "    samples = cfg[\"plot_samples\"][1]\n",
    "    samples.extend(cfg[\"plot_samples\"][0])\n",
    "    dataset = Subset(dataset, samples)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=spec[\"batch_size\"],\n",
    "    num_workers=cfg.get(\"num_workers\"),\n",
    "    persistent_workers=bool(cfg.get(\"num_workers\")),\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, scale in tqdm(zip(names, scales), total=len(names)):\n",
    "    print(model_name, scale)\n",
    "    ### Pack Options\n",
    "    model_dir = Path(cfg[\"model_dir\"])\n",
    "    model_paths = list(model_dir.glob(f\"**/*{model_name}*last.pth\"))\n",
    "    if len(model_paths) != 1:\n",
    "        raise FileNotFoundError()\n",
    "    model_spec = torch.load(model_paths[0], map_location=\"cuda\")[\"model\"]\n",
    "    model = models.make(model_spec, load_sd=True).to(\"cuda\")\n",
    "    opts = dict(\n",
    "        model_name=model_name,\n",
    "        model_path=model_paths[0],\n",
    "        save_path=Path(cfg[\"inference_output_dir\"] or f\"inference/{model_name}\"),\n",
    "        rgb_range=cfg[\"rgb_range\"],\n",
    "        shave_factor=0,  # pixels to shave (edges may include NaN)\n",
    "        ids=cfg[\"plot_samples\"],  # Sample IDs\n",
    "        mag=cfg[\"test_dataset\"][\"dataset\"][\"args\"][\"load_magnetics\"],\n",
    "        grv=cfg[\"test_dataset\"][\"dataset\"][\"args\"][\"load_gravity\"],\n",
    "        eval_bsize=cfg[\"eval_bsize\"],\n",
    "        limit_to_plots=cfg[\"limit_to_plots\"],\n",
    "        gt_list=cfg[\"test_dataset\"][\"dataset\"][\"args\"][\"root_path\"],\n",
    "    )\n",
    "\n",
    "    scale_min = spec[\"wrapper\"][\"args\"][\"scale_min\"]\n",
    "    scale_max = spec[\"wrapper\"][\"args\"][\"scale_max\"]\n",
    "\n",
    "    print(\n",
    "        f\"\\nModel: {opts['model_path'].absolute()}\\n\"\n",
    "        f\"Saving to: {opts['save_path'].absolute()}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot real data via HRLR dataset ###\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "from comet_ml import Experiment\n",
    "import numpy as np\n",
    "import piq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "import models\n",
    "import utils\n",
    "from test import reshape, eval_psnr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 10\n",
    "\n",
    "with open(r\"D:\\luke\\lte_geo\\configs\\train_swinir-lte_geo.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "spec = config.get(\"train_dataset\")\n",
    "\n",
    "dataset = datasets.make(spec[\"dataset\"])\n",
    "dataset = datasets.make(spec[\"wrapper\"], args={\"dataset\": dataset})\n",
    "\n",
    "dataset.dataset.scale = 6\n",
    "\n",
    "lr = dataset.dataset[index][\"lr_grid\"]\n",
    "gt = dataset.dataset[index][\"hr_grid\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(lr.squeeze())\n",
    "plt.figure()\n",
    "plt.imshow(gt.squeeze())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do Inference ###\n",
    "# results_dict = {}\n",
    "# custom_results_dict = {}\n",
    "\n",
    "# scale_min = 4\n",
    "# scale_max = 4\n",
    "\n",
    "# pbar_m = tqdm(range(scale_min, scale_max + 1))\n",
    "# for scale in pbar_m:\n",
    "#     pbar_m.set_description(f\"{scale}x scale\")\n",
    "#     opts[\"shave\"] = scale * opts[\"shave_factor\"]\n",
    "\n",
    "#     # lazy way to reset custom grid opts\n",
    "#     opts[\"ids\"] = cfg[\"plot_samples\"]\n",
    "#     opts[\"gt\"] = None\n",
    "#     opts[\"set\"] = \"test\"\n",
    "\n",
    "#     dataset.scale = scale\n",
    "#     dataset.scale_min = scale\n",
    "#     dataset.scale_max = scale\n",
    "#     if cfg[\"limit_to_plots\"]:\n",
    "#         # Not sure how to better handle Subset dataset\n",
    "#         dataset.dataset.scale = scale\n",
    "#         dataset.dataset.scale_min = scale\n",
    "#         dataset.dataset.scale_max = scale\n",
    "\n",
    "#     results = eval(model, scale, loader, opts, cfg=cfg)\n",
    "#     results_dict[f\"{scale}x\"] = results\n",
    "#     pbar_m.write(f\"{scale}x scale - Mean:\")\n",
    "#     pbar_m.write(\n",
    "#         \", \".join(\n",
    "#             f\"{metric_name}: {metric_value:.4f}\"\n",
    "#             for metric_name, metric_value in results.items()\n",
    "#         )\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_results(results_dict, opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i, batch in enumerate(loader):\n",
    "    inp = batch[\"inp\"].to(\"cuda\", non_blocking=True)\n",
    "    coord = batch[\"coord\"].to(\"cuda\", non_blocking=True)\n",
    "    cell = batch[\"cell\"].to(\"cuda\", non_blocking=True)\n",
    "    # batch[\"gt\"] = batch[\"gt\"].to(\"cuda\", non_blocking=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if opts[\"eval_bsize\"]:\n",
    "            pred = batched_predict(model, inp, coord, cell, opts[\"eval_bsize\"])\n",
    "        else:\n",
    "            pred = model(inp, coord, cell)\n",
    "\n",
    "    pred, batch = reshape(batch, h_pad=0, w_pad=0, coord=coord, pred=pred)\n",
    "    lr = batch[\"inp\"].detach().cpu().squeeze().numpy()\n",
    "    hr = batch[\"gt\"].detach().cpu().squeeze().numpy()\n",
    "    sr = pred.detach().cpu().squeeze().numpy()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "from inference import plot_canny\n",
    "\n",
    "fig, [ax0, ax1] = plt.subplots(1, 2)\n",
    "\n",
    "c0 = ax0.imshow(sr, cmap=cc.cm.CET_L8, origin=\"lower\", interpolation=\"nearest\")\n",
    "plt.colorbar(c0, orientation=\"horizontal\", ax=ax0)\n",
    "plot_canny(\n",
    "    ax1,\n",
    "    hr,\n",
    "    sr,\n",
    "    np.array(Image.fromarray(lr).resize(hr.shape, Image.Resampling.BICUBIC)),\n",
    "    sigma=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(hr)\n",
    "mask[:, ::4] = 1\n",
    "\n",
    "# cmap.set_bad(alpha=0)\n",
    "fig, ax = plt.subplots(1, 1, constrained_layout=True, figsize=(10, 10), dpi=600)\n",
    "cgry = ax.imshow(hr, cmap=cc.cm.CET_L1, interpolation=\"nearest\", origin=\"lower\")\n",
    "cclr = ax.imshow(\n",
    "    hr, cmap=cc.cm.CET_L8, interpolation=\"nearest\", origin=\"lower\", alpha=mask\n",
    ")\n",
    "plt.colorbar(mappable=cgry, ax=ax, orientation=\"horizontal\", label=\"Unsampled\")\n",
    "plt.colorbar(mappable=cclr, ax=ax, orientation=\"horizontal\", label=\"Line Sampled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('lte')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05781e052d06f1cdf1bacfc411fbd68c6efd2f4a84155de6239f578257f46815"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
