{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ccbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a2ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configuration\n",
    "model_path = \"D:/luke/edsr-baseline-lte.pth\"\n",
    "# model_path = \"D:/luke/lte_geo/save/_train_swinir-lte_geo/230516-1847_resident_crumble_3867/resident_crumble_3867_epoch-last.pth\"\n",
    "\n",
    "# image configuration\n",
    "lr_path = './demo/Urban100_img012x2.png'\n",
    "gt_path = './demo/Urban100_img012.png'\n",
    "scale = 2\n",
    "xx = 700\n",
    "yy = 550\n",
    "obs_size = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea5f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from test import reshape\n",
    "from utils import to_pixel_samples\n",
    "\n",
    "# load model\n",
    "model_spec = torch.load(model_path)['model']\n",
    "model = models.make(model_spec, load_sd=True).cuda()\n",
    "\n",
    "# load image\n",
    "img_lr = transforms.ToTensor()(Image.open(lr_path).convert('RGB'))\n",
    "img_gt = transforms.ToTensor()(Image.open(gt_path).convert('RGB'))\n",
    "img_gt = img_gt.unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a464e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "inp = ((img_lr.unsqueeze(0).cuda() - 0.5) / 0.5)#.unsqueeze(0)\n",
    "\n",
    "hr_coord, hr_val = to_pixel_samples(img_gt)\n",
    "\n",
    "hr_cell = torch.ones_like(hr_coord)\n",
    "hr_cell[:, 0] *= 2 / img_gt.shape[-2]\n",
    "hr_cell[:, 1] *= 2 / img_gt.shape[-1]\n",
    "hr_coord = hr_coord.unsqueeze(0)\n",
    "hr_cell = hr_cell.unsqueeze(0)\n",
    "\n",
    "print(img_gt.shape, inp.shape, hr_coord.shape, hr_cell.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fd9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sr = (\n",
    "        model(\n",
    "            inp.flip(-2),\n",
    "            hr_coord.to(\"cuda\", non_blocking=True),\n",
    "            hr_cell.to(\"cuda\", non_blocking=True),\n",
    "        )\n",
    "        .detach()\n",
    "        .cpu()\n",
    "    )\n",
    "    freq = model.coeff.flip(-2)\n",
    "    coef = model.freqq.flip(-2)\n",
    "\n",
    "    # model.gen_feat(inp.flip(-2)) # due to a digital image coordinate conventions (https://blogs.mathworks.com/steve/2011/08/26/digital-image-processing-using-matlab-digital-image-representation/)\n",
    "    # freq = model.freq(model.feat).flip(-2)\n",
    "    # coef = model.coef(model.feat).flip(-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c54b16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "\n",
    "# Display GT\n",
    "im = Image.open(gt_path).convert('RGB')\n",
    "draw = ImageDraw.Draw(im)\n",
    "draw.rectangle([yy-obs_size//2, xx-obs_size//2, yy+obs_size//2, xx+obs_size//2], outline=\"red\", width=3)\n",
    "display(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, batch = reshape(dict(inp=inp, coord=hr_coord, gt=img_gt), 0, 0, hr_coord, sr)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(inp.cpu().squeeze().permute(1,2,0).numpy())\n",
    "plt.figure()\n",
    "plt.imshow(sr.cpu().squeeze().permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Display Fourier Feature Space\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "freq_x = torch.stack(torch.split(freq, 2, dim=1), dim=2)[0, 1, :, xx//scale, yy//scale].cpu().numpy()\n",
    "freq_y = torch.stack(torch.split(freq, 2, dim=1), dim=2)[0, 0, :, xx//scale, yy//scale].cpu().numpy()\n",
    "mag    = (coef[0, :freq.shape[1]//2, xx//scale, yy//scale]**2 + coef[0, freq.shape[1]//2:, xx//scale, yy//scale]**2).cpu().numpy()\n",
    "sc = plt.scatter(freq_x, freq_y, c=mag, vmin=0, vmax=max(mag)/4, s=None, cmap='bwr')\n",
    "# plt.colorbar(sc)\n",
    "plt.xticks(np.linspace(-1.5, 1.5, 5))\n",
    "plt.yticks(np.linspace(-1.5, 1.5, 5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
